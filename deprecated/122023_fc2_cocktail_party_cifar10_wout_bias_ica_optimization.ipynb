{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umityigitbsrn/miniconda3/envs/pytorch-stable/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from model import Network\n",
    "from data import load_cifar10_dataloaders, whitening_transformation\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from criterion import ReconstructImageFromFCLoss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:16:44.136214207Z",
     "start_time": "2023-12-21T08:16:43.177310895Z"
    }
   },
   "id": "42eb36ed57ad71e5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:16:45.923397317Z",
     "start_time": "2023-12-21T08:16:44.176482779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load to model\n",
    "model_config = './model_config/fc2_cocktail_party_instance_wout_bias.json'\n",
    "checkpoint_path = './checkpoints/121923_fc2_cocktail_party_cifar10_pretraining_wout_bias.pth'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Network(model_config)\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "# get val loader\n",
    "normalize_mean, normalize_std = (0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)\n",
    "batch_size = 8\n",
    "data_path = './data'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(normalize_mean, normalize_std),\n",
    "])\n",
    "\n",
    "_, val_dataloader = load_cifar10_dataloaders(data_path, batch_size, transform)\n",
    "selected_val_batch_data, selected_val_batch_label = next(iter(val_dataloader))\n",
    "selected_val_batch_data = selected_val_batch_data.to(device)\n",
    "selected_val_batch_label = selected_val_batch_label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([256, 3072]), torch.Size([10, 256])]\n"
     ]
    }
   ],
   "source": [
    "# receiving gradients\n",
    "model.zero_grad()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "output = model(selected_val_batch_data.reshape(batch_size, -1))\n",
    "loss = criterion(output, selected_val_batch_label)\n",
    "loss.backward()\n",
    "gradient_of_layers = []\n",
    "for param in model.parameters():\n",
    "    gradient_of_layers.append(param.grad.data.clone().to('cpu'))\n",
    "print([x.size() for x in gradient_of_layers])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:16:46.456923327Z",
     "start_time": "2023-12-21T08:16:45.924823316Z"
    }
   },
   "id": "9fd43b89714d7e39"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pca_whitened_gradients = []\n",
    "zca_whitened_gradients = []\n",
    "for gradient in gradient_of_layers:\n",
    "    pca_whitened_gradient, zca_whitened_gradient = whitening_transformation(gradient)\n",
    "    pca_whitened_gradients.append(pca_whitened_gradient)\n",
    "    zca_whitened_gradients.append(zca_whitened_gradient)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:16:53.727875731Z",
     "start_time": "2023-12-21T08:16:46.458911090Z"
    }
   },
   "id": "bca16f196cda4d87"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.0979433059692383\n",
      "loss: 0.853891134262085\n",
      "loss: 0.8182715773582458\n",
      "loss: 0.8152432441711426\n",
      "loss: 0.8132375478744507\n",
      "loss: 0.8115373253822327\n",
      "loss: 0.8100262880325317\n",
      "loss: 0.8089626431465149\n",
      "loss: 0.8082752227783203\n",
      "loss: 0.8077040314674377\n",
      "loss: 0.8072206974029541\n",
      "loss: 0.8068822622299194\n",
      "loss: 0.8065118789672852\n",
      "loss: 0.8063374161720276\n",
      "loss: 0.8061027526855469\n",
      "loss: 0.8059698343276978\n",
      "loss: 0.8058511018753052\n",
      "loss: 0.8057987093925476\n",
      "loss: 0.8056550025939941\n",
      "loss: 0.8055974841117859\n",
      "loss: 0.8055146336555481\n",
      "loss: 0.8054519891738892\n",
      "loss: 0.8054258823394775\n",
      "loss: 0.8053689002990723\n",
      "loss: 0.8053085803985596\n",
      "loss: 0.8052671551704407\n"
     ]
    }
   ],
   "source": [
    "# criterion output testing\n",
    "unmixing_matrix = torch.rand((selected_val_batch_data.size(0), gradient_of_layers[0].size(0)), requires_grad=True)\n",
    "reconstruction_loss = ReconstructImageFromFCLoss(32, 32, 3, 1, 1, 1)\n",
    "optimizer = torch.optim.Adam([unmixing_matrix])\n",
    "\n",
    "for iter_idx in range(25000):\n",
    "    optimizer.zero_grad()\n",
    "    # out_score, non_gaussianity_score, total_variance_score, mutual_independence_score\n",
    "    loss, _, _, _ = reconstruction_loss(unmixing_matrix, zca_whitened_gradients[0])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (iter_idx + 1) % 1000 == 0 or iter_idx == 0:\n",
    "        print('loss: {}'.format(loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:18:17.397937504Z",
     "start_time": "2023-12-21T08:17:40.436326086Z"
    }
   },
   "id": "d74e4a85e6c0a2e7"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    estimated_img = unmixing_matrix @ zca_whitened_gradients[0]\n",
    "    img = transforms.ToPILImage()(-1 * torch.clamp(estimated_img[5].reshape(3, 32, 32), min=-1, max=1) * 100)\n",
    "    img.show()\n",
    "    img = transforms.ToPILImage()(torch.clamp(selected_val_batch_data[5].reshape(3, 32, 32), min=-1, max=1))\n",
    "    img.show()\n",
    "    # print(estimated_img[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:22:34.041347592Z",
     "start_time": "2023-12-21T08:22:34.019060378Z"
    }
   },
   "id": "807441fb5cebe1d6"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0])\n",
      "torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    clamped_img = torch.clamp(estimated_img[0].reshape(3, 32, 32), min=-1, max=1)\n",
    "    print(clamped_img[clamped_img == -1].shape)\n",
    "    print(clamped_img[clamped_img == 1].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T07:42:32.281807152Z",
     "start_time": "2023-12-21T07:42:32.238458793Z"
    }
   },
   "id": "7846d02b99aa5406"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 3.2783e-04,  2.9368e-04,  3.0880e-04,  ...,  4.9177e-04,\n           5.1527e-04,  5.2216e-04],\n         [ 2.7950e-04,  2.5961e-04,  2.6367e-04,  ...,  3.4911e-04,\n           3.9457e-04,  3.9479e-04],\n         [ 1.7792e-04,  1.3845e-04,  1.4941e-04,  ...,  3.0867e-04,\n           3.8751e-04,  4.5424e-04],\n         ...,\n         [-4.8327e-05, -1.1369e-05,  5.7595e-05,  ..., -9.0523e-05,\n          -4.6151e-05, -5.3062e-05],\n         [-2.3185e-04, -1.5868e-04, -4.3910e-05,  ..., -1.1516e-04,\n          -1.0162e-04, -5.3834e-05],\n         [-2.3476e-04, -2.0716e-04, -1.7674e-04,  ..., -1.2411e-04,\n          -1.1664e-04, -2.0626e-05]],\n\n        [[ 2.6655e-04,  2.6097e-04,  2.8234e-04,  ...,  5.3675e-04,\n           5.4891e-04,  5.5572e-04],\n         [ 2.3377e-04,  2.4697e-04,  2.6934e-04,  ...,  4.1941e-04,\n           4.3809e-04,  4.2729e-04],\n         [ 1.4929e-04,  1.5777e-04,  1.9760e-04,  ...,  3.4826e-04,\n           4.1596e-04,  4.6848e-04],\n         ...,\n         [-5.0159e-05, -2.1224e-05,  4.4790e-05,  ..., -1.6359e-04,\n          -1.1424e-04, -1.1485e-04],\n         [-2.0826e-04, -1.3613e-04, -3.3480e-05,  ..., -1.6975e-04,\n          -1.5772e-04, -1.0461e-04],\n         [-2.1862e-04, -1.7460e-04, -1.5209e-04,  ..., -1.5777e-04,\n          -1.5806e-04, -6.8794e-05]],\n\n        [[ 1.1957e-04,  1.2168e-04,  1.3567e-04,  ...,  3.9465e-04,\n           3.9260e-04,  3.9234e-04],\n         [ 1.1818e-04,  1.2998e-04,  1.6207e-04,  ...,  2.8986e-04,\n           3.0188e-04,  2.8690e-04],\n         [ 5.3605e-05,  6.4105e-05,  1.3124e-04,  ...,  2.7036e-04,\n           3.0166e-04,  3.4027e-04],\n         ...,\n         [-2.7832e-05, -9.4176e-06,  4.0080e-05,  ..., -1.6859e-04,\n          -1.2478e-04, -1.2051e-04],\n         [-1.6574e-04, -1.0742e-04, -2.3264e-05,  ..., -1.6234e-04,\n          -1.5775e-04, -1.1367e-04],\n         [-1.9830e-04, -1.6510e-04, -1.4574e-04,  ..., -1.5202e-04,\n          -1.6098e-04, -9.1396e-05]]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimated_img[0].reshape(3, 32, 32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:19:43.314232006Z",
     "start_time": "2023-12-21T08:19:43.271663887Z"
    }
   },
   "id": "59cce114b947013b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
