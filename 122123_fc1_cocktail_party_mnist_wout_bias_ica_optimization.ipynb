{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from model import Network\n",
    "from data import load_mnist_dataloaders, WhiteningTransformation\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from criterion import ReconstructImageFromFCLoss"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "42eb36ed57ad71e5"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-21T20:41:27.674559449Z",
     "start_time": "2023-12-21T20:41:26.946154027Z"
    }
   },
   "outputs": [],
   "source": [
    "# load to model\n",
    "model_config = './model_config/fc1_cocktail_party_mnist_instance.json'\n",
    "checkpoint_path = './checkpoints/122123_fc1_cocktail_party_mnist_pretraining_wout_bias.pth'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Network(model_config)\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "# get val loader\n",
    "normalize_mean, normalize_std = (0.1307,), (0.3081,)\n",
    "batch_size = 4\n",
    "data_path = './data'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(normalize_mean, normalize_std),\n",
    "])\n",
    "\n",
    "_, val_dataloader = load_mnist_dataloaders(data_path, batch_size, transform)\n",
    "selected_val_batch_data, selected_val_batch_label = next(iter(val_dataloader))\n",
    "selected_val_batch_data = selected_val_batch_data.to(device)\n",
    "selected_val_batch_label = selected_val_batch_label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([10, 784])]\n"
     ]
    }
   ],
   "source": [
    "# receiving gradients\n",
    "model.zero_grad()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "output = model(selected_val_batch_data.reshape(batch_size, -1))\n",
    "loss = criterion(output, selected_val_batch_label)\n",
    "loss.backward()\n",
    "gradient_of_layers = []\n",
    "for param in model.parameters():\n",
    "    gradient_of_layers.append(param.grad.data.clone().to('cpu'))\n",
    "print([x.size() for x in gradient_of_layers])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T20:41:28.204954976Z",
     "start_time": "2023-12-21T20:41:27.675553033Z"
    }
   },
   "id": "9fd43b89714d7e39"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "whitening_transform = WhiteningTransformation()\n",
    "whitened_gradient = torch.from_numpy(whitening_transform.transform(gradient_of_layers[0].detach().numpy().T)).to(torch.float32).T"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6db76726297c0ab2"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.9434760808944702\n",
      "loss: 0.9226415753364563\n",
      "loss: 0.9137480854988098\n",
      "loss: 0.9062380790710449\n",
      "loss: 0.9000566601753235\n",
      "loss: 0.8952429294586182\n",
      "loss: 0.8913980722427368\n",
      "loss: 0.8887266516685486\n",
      "loss: 0.8867244720458984\n",
      "loss: 0.8849146962165833\n",
      "loss: 0.8839080333709717\n",
      "loss: 0.8831490874290466\n",
      "loss: 0.8826785087585449\n",
      "loss: 0.8818979263305664\n",
      "loss: 0.881306529045105\n",
      "loss: 0.8813421726226807\n",
      "loss: 0.8807418346405029\n",
      "loss: 0.8805824518203735\n",
      "loss: 0.8811609148979187\n",
      "loss: 0.8812450766563416\n",
      "loss: 0.8800931572914124\n",
      "loss: 0.8802552223205566\n",
      "loss: 0.8800516724586487\n",
      "loss: 0.8802169561386108\n",
      "loss: 0.8801079392433167\n",
      "loss: 0.8804312348365784\n"
     ]
    }
   ],
   "source": [
    "from criterion import ReconstructImageFromFCLoss\n",
    "# criterion output testing\n",
    "unmixing_matrix = torch.rand((selected_val_batch_data.size(0), gradient_of_layers[0].size(0)), requires_grad=True)\n",
    "reconstruction_loss = ReconstructImageFromFCLoss(28, 28, 1, 1, 1, 1)\n",
    "optimizer = torch.optim.Adam([unmixing_matrix])\n",
    "\n",
    "for iter_idx in range(25000):\n",
    "    optimizer.zero_grad()\n",
    "    # out_score, non_gaussianity_score, total_variance_score, mutual_independence_score\n",
    "    loss, _, _, _ = reconstruction_loss(unmixing_matrix, whitened_gradient)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (iter_idx + 1) % 1000 == 0 or iter_idx == 0:\n",
    "        print('loss: {}'.format(loss.item()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "271ed464941bfd3a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
