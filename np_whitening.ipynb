{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:48:24.592116762Z",
     "start_time": "2023-12-21T23:48:24.581164413Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from model import Network\n",
    "from data import load_mnist_dataloaders\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:48:25.424806095Z",
     "start_time": "2023-12-21T23:48:25.415145470Z"
    }
   },
   "id": "b8568ca38057dd74"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# load to model\n",
    "model_config = './model_config/fc1_cocktail_party_mnist_instance.json'\n",
    "checkpoint_path = './checkpoints/122123_fc1_cocktail_party_mnist_pretraining_wout_bias.pth'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Network(model_config)\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "# get val loader\n",
    "normalize_mean, normalize_std = (0.1307,), (0.3081,)\n",
    "batch_size = 8\n",
    "data_path = './data'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(normalize_mean, normalize_std),\n",
    "])\n",
    "\n",
    "_, val_dataloader = load_mnist_dataloaders(data_path, batch_size, transform)\n",
    "selected_val_batch_data, selected_val_batch_label = next(iter(val_dataloader))\n",
    "selected_val_batch_data = selected_val_batch_data.to(device)\n",
    "selected_val_batch_label = selected_val_batch_label.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:48:27.639329733Z",
     "start_time": "2023-12-21T23:48:27.009746040Z"
    }
   },
   "id": "2e68cc0665eead9f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([10, 784])]\n"
     ]
    }
   ],
   "source": [
    "# receiving gradients\n",
    "model.zero_grad()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "output = model(selected_val_batch_data.reshape(batch_size, -1))\n",
    "loss = criterion(output, selected_val_batch_label)\n",
    "loss.backward()\n",
    "gradient_of_layers = []\n",
    "for param in model.parameters():\n",
    "    gradient_of_layers.append(param.grad.data.clone().to('cpu'))\n",
    "print([x.size() for x in gradient_of_layers])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:48:28.351705947Z",
     "start_time": "2023-12-21T23:48:27.641133067Z"
    }
   },
   "id": "901405c4a4b7a792"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def demean(X):\n",
    "    # Note that this is the same as J = (I - 11^T/n)\n",
    "    ones = np.ones((X.shape[0], 1))\n",
    "    J = np.identity(X.shape[0]) - ((np.matmul(ones, ones.T)) / X.shape[0])\n",
    "    return np.matmul(J, X)\n",
    "\n",
    "def project(X, V_trans):\n",
    "    # Note that this is the same as V\n",
    "    return np.matmul(X, V_trans.T)\n",
    "\n",
    "def scale(X, S):\n",
    "    # Note that this is the same as S^{-1}\n",
    "    return np.multiply(X, (1 / S))\n",
    "\n",
    "def unrotate(X, V):\n",
    "    # Note that this is the same as V^{T}\n",
    "    return np.matmul(X, V)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:22:54.296426097Z",
     "start_time": "2023-12-21T23:22:54.294802443Z"
    }
   },
   "id": "5325eebf95962c28"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10)\n"
     ]
    }
   ],
   "source": [
    "gradient = demean(gradient_of_layers[0].detach().numpy().T)\n",
    "print(gradient.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:22:54.327045955Z",
     "start_time": "2023-12-21T23:22:54.296457330Z"
    }
   },
   "id": "2f8206b28304fa01"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "U, S, V_trans = np.linalg.svd(gradient)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:22:55.512043104Z",
     "start_time": "2023-12-21T23:22:55.505067061Z"
    }
   },
   "id": "8cef2f7f6d68744a"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(784, 784)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:44:43.360526838Z",
     "start_time": "2023-12-21T23:44:43.352867132Z"
    }
   },
   "id": "f7afc77a8fefa864"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(S.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:22:56.042056822Z",
     "start_time": "2023-12-21T23:22:56.038689678Z"
    }
   },
   "id": "6eb12b2cf84b92e3"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "x_proj = project(gradient, V_trans)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:22:56.598854649Z",
     "start_time": "2023-12-21T23:22:56.593847399Z"
    }
   },
   "id": "78d4273fb569e304"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "x_scaled = scale(x_proj, S)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:22:57.121325589Z",
     "start_time": "2023-12-21T23:22:57.119811106Z"
    }
   },
   "id": "9e1ab1ad1ec32cfc"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "x_unrotated = unrotate(x_scaled, V_trans)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:22:57.686624146Z",
     "start_time": "2023-12-21T23:22:57.683045978Z"
    }
   },
   "id": "e938ac60bce5822e"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "whitened_gradient = x_unrotated.T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:22:58.245189281Z",
     "start_time": "2023-12-21T23:22:58.243723509Z"
    }
   },
   "id": "55c79e5221a209f6"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-4.57331351e-05, -1.51589345e-05, -2.25460471e-03, ...,\n        -1.05363532e-02,  1.57396371e-02,  4.67932431e-03],\n       [-4.57331351e-05, -1.51589345e-05, -2.25460471e-03, ...,\n        -1.05363532e-02,  1.57396371e-02,  4.67932431e-03],\n       [-4.57331351e-05, -1.51589345e-05, -2.25460471e-03, ...,\n        -1.05363532e-02,  1.57396371e-02,  4.67932431e-03],\n       ...,\n       [-4.57331351e-05, -1.51589345e-05, -2.25460471e-03, ...,\n        -1.05363532e-02,  1.57396371e-02,  4.67932431e-03],\n       [-4.57331351e-05, -1.51589345e-05, -2.25460471e-03, ...,\n        -1.05363532e-02,  1.57396371e-02,  4.67932431e-03],\n       [-4.57331351e-05, -1.51589345e-05, -2.25460471e-03, ...,\n        -1.05363532e-02,  1.57396371e-02,  4.67932431e-03]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:22:59.005677191Z",
     "start_time": "2023-12-21T23:22:59.003864064Z"
    }
   },
   "id": "e90c4bc67edde2a5"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "whitened_gradient = torch.from_numpy(whitened_gradient).to(torch.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:23:00.579586695Z",
     "start_time": "2023-12-21T23:23:00.576508298Z"
    }
   },
   "id": "79e356f7b7173837"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n        [ 0.0033,  0.0033,  0.0033,  ...,  0.0033,  0.0033,  0.0033],\n        [-0.0033, -0.0033, -0.0033,  ..., -0.0033, -0.0033, -0.0033],\n        ...,\n        [-0.0094, -0.0094, -0.0094,  ..., -0.0094, -0.0094, -0.0094],\n        [ 0.0087,  0.0087,  0.0087,  ...,  0.0087,  0.0087,  0.0087],\n        [ 0.0076,  0.0076,  0.0076,  ...,  0.0076,  0.0076,  0.0076]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitened_gradient"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:23:01.156861125Z",
     "start_time": "2023-12-21T23:23:01.153188780Z"
    }
   },
   "id": "dabb8f478fcac461"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(784, 10)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_of_layers[0].detach().numpy().T.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:50:58.467766736Z",
     "start_time": "2023-12-21T23:50:58.426854119Z"
    }
   },
   "id": "4e0b96a47c9b255b"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from data import WhiteningTransformation\n",
    "transform = WhiteningTransformation()\n",
    "whitened_gradient = torch.from_numpy(transform.transform(gradient_of_layers[0].detach().numpy().T)).to(torch.float32).T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:51:30.835641348Z",
     "start_time": "2023-12-21T23:51:30.792195692Z"
    }
   },
   "id": "bce31964354b97bc"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.9434760808944702\n",
      "loss: 0.9226415753364563\n",
      "loss: 0.9137480854988098\n",
      "loss: 0.9062380790710449\n",
      "loss: 0.9000566601753235\n",
      "loss: 0.8952429294586182\n",
      "loss: 0.8913980722427368\n",
      "loss: 0.8887266516685486\n",
      "loss: 0.8867244720458984\n",
      "loss: 0.8849146962165833\n",
      "loss: 0.8839080333709717\n",
      "loss: 0.8831490874290466\n",
      "loss: 0.8826785087585449\n",
      "loss: 0.8818979263305664\n",
      "loss: 0.881306529045105\n",
      "loss: 0.8813421726226807\n",
      "loss: 0.8807418346405029\n",
      "loss: 0.8805824518203735\n",
      "loss: 0.8811609148979187\n",
      "loss: 0.8812450766563416\n",
      "loss: 0.8800931572914124\n",
      "loss: 0.8802552223205566\n",
      "loss: 0.8800516724586487\n",
      "loss: 0.8802169561386108\n",
      "loss: 0.8801079392433167\n",
      "loss: 0.8804312348365784\n"
     ]
    }
   ],
   "source": [
    "from criterion import ReconstructImageFromFCLoss\n",
    "# criterion output testing\n",
    "unmixing_matrix = torch.rand((selected_val_batch_data.size(0), gradient_of_layers[0].size(0)), requires_grad=True)\n",
    "reconstruction_loss = ReconstructImageFromFCLoss(28, 28, 1, 1, 1, 1)\n",
    "optimizer = torch.optim.Adam([unmixing_matrix])\n",
    "\n",
    "for iter_idx in range(25000):\n",
    "    optimizer.zero_grad()\n",
    "    # out_score, non_gaussianity_score, total_variance_score, mutual_independence_score\n",
    "    loss, _, _, _ = reconstruction_loss(unmixing_matrix, whitened_gradient)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (iter_idx + 1) % 1000 == 0 or iter_idx == 0:\n",
    "        print('loss: {}'.format(loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:52:00.546211896Z",
     "start_time": "2023-12-21T23:51:32.844156321Z"
    }
   },
   "id": "b886331edcc0694a"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:25756): EOG-CRITICAL **: 15:52:34.647: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25756): GLib-GIO-CRITICAL **: 15:52:34.647: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n",
      "\n",
      "(eog:25756): EOG-CRITICAL **: 15:52:34.647: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25756): GLib-GIO-CRITICAL **: 15:52:34.647: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n",
      "\n",
      "(eog:25756): EOG-CRITICAL **: 15:52:34.647: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25756): GLib-GIO-CRITICAL **: 15:52:34.647: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n",
      "\n",
      "(eog:25756): EOG-CRITICAL **: 15:52:34.755: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25756): GLib-GIO-CRITICAL **: 15:52:34.755: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n",
      "\n",
      "(eog:25756): EOG-CRITICAL **: 15:52:34.771: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25756): GLib-GIO-CRITICAL **: 15:52:34.771: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    estimated_img = unmixing_matrix @ whitened_gradient\n",
    "    for estimate in estimated_img:\n",
    "        img = transforms.ToPILImage()(torch.clamp(estimate.reshape(1, 28, 28), min=-1, max=1))\n",
    "        # imshow(np.asarray(img))\n",
    "        img.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:52:34.780489344Z",
     "start_time": "2023-12-21T23:52:34.357611381Z"
    }
   },
   "id": "8de1f262e31f69f4"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:25916): EOG-CRITICAL **: 15:52:59.957: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25916): GLib-GIO-CRITICAL **: 15:52:59.957: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n",
      "\n",
      "(eog:25916): EOG-CRITICAL **: 15:52:59.957: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25916): GLib-GIO-CRITICAL **: 15:52:59.957: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n",
      "\n",
      "(eog:25916): EOG-CRITICAL **: 15:53:00.007: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25916): GLib-GIO-CRITICAL **: 15:53:00.007: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n",
      "\n",
      "(eog:25916): EOG-CRITICAL **: 15:53:00.062: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25916): GLib-GIO-CRITICAL **: 15:53:00.062: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n",
      "\n",
      "(eog:25916): EOG-CRITICAL **: 15:53:00.062: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25916): GLib-GIO-CRITICAL **: 15:53:00.062: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n",
      "\n",
      "(eog:25916): EOG-CRITICAL **: 15:53:00.128: eog_image_get_file: assertion 'EOG_IS_IMAGE (img)' failed\n",
      "\n",
      "(eog:25916): GLib-GIO-CRITICAL **: 15:53:00.128: g_file_equal: assertion 'G_IS_FILE (file1)' failed\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # estimated_img = unmixing_matrix @ whitened_gradient\n",
    "    for img_arr in selected_val_batch_data:\n",
    "        img = transforms.ToPILImage()(torch.clamp(img_arr.reshape(1, 28, 28), min=-1, max=1))\n",
    "        # imshow(np.asarray(img))\n",
    "        img.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T23:53:00.141676439Z",
     "start_time": "2023-12-21T23:52:59.717792232Z"
    }
   },
   "id": "e232fb94acc4ff30"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
