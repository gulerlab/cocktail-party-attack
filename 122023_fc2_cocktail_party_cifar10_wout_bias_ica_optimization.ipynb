{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umityigitbsrn/miniconda3/envs/pytorch-stable/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from model import Network\n",
    "from data import load_cifar10_dataloaders, whitening_transformation\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from criterion import ReconstructImageFromFCLoss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:10:52.201155974Z",
     "start_time": "2023-12-21T08:10:51.229297856Z"
    }
   },
   "id": "42eb36ed57ad71e5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:10:53.977116981Z",
     "start_time": "2023-12-21T08:10:52.236615521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load to model\n",
    "model_config = './model_config/fc2_cocktail_party_instance_wout_bias.json'\n",
    "checkpoint_path = './checkpoints/121923_fc2_cocktail_party_cifar10_pretraining_wout_bias.pth'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = Network(model_config)\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "# get val loader\n",
    "normalize_mean, normalize_std = (0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)\n",
    "batch_size = 8\n",
    "data_path = './data'\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(normalize_mean, normalize_std),\n",
    "])\n",
    "\n",
    "_, val_dataloader = load_cifar10_dataloaders(data_path, batch_size, transform)\n",
    "selected_val_batch_data, selected_val_batch_label = next(iter(val_dataloader))\n",
    "selected_val_batch_data = selected_val_batch_data.to(device)\n",
    "selected_val_batch_label = selected_val_batch_label.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([256, 3072]), torch.Size([10, 256])]\n"
     ]
    }
   ],
   "source": [
    "# receiving gradients\n",
    "model.zero_grad()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "output = model(selected_val_batch_data.reshape(batch_size, -1))\n",
    "loss = criterion(output, selected_val_batch_label)\n",
    "loss.backward()\n",
    "gradient_of_layers = []\n",
    "for param in model.parameters():\n",
    "    gradient_of_layers.append(param.grad.data.clone().to('cpu'))\n",
    "print([x.size() for x in gradient_of_layers])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:10:54.493716239Z",
     "start_time": "2023-12-21T08:10:53.978158380Z"
    }
   },
   "id": "9fd43b89714d7e39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_whitened_gradients = []\n",
    "zca_whitened_gradients = []\n",
    "for gradient in gradient_of_layers:\n",
    "    pca_whitened_gradient, zca_whitened_gradient = whitening_transformation(gradient)\n",
    "    pca_whitened_gradients.append(pca_whitened_gradient)\n",
    "    zca_whitened_gradients.append(zca_whitened_gradient)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-21T08:10:55.649754901Z"
    }
   },
   "id": "bca16f196cda4d87"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.9379727840423584\n",
      "loss: 0.9412828087806702\n",
      "loss: 0.9356341361999512\n",
      "loss: 0.932887077331543\n",
      "loss: 0.9315226078033447\n",
      "loss: 0.9314039349555969\n",
      "loss: 0.9289105534553528\n",
      "loss: 0.9283108711242676\n",
      "loss: 0.9250630140304565\n",
      "loss: 0.9226387143135071\n",
      "loss: 0.9224544167518616\n",
      "loss: 0.9200116991996765\n",
      "loss: 0.9200348854064941\n",
      "loss: 0.9200003743171692\n",
      "loss: 0.9200664758682251\n",
      "loss: 0.9199835062026978\n",
      "loss: 0.9199564456939697\n",
      "loss: 0.9200427532196045\n",
      "loss: 0.9188419580459595\n",
      "loss: 0.9160979390144348\n",
      "loss: 0.9162095785140991\n",
      "loss: 0.9161527752876282\n",
      "loss: 0.9160701036453247\n",
      "loss: 0.9161638021469116\n",
      "loss: 0.9161427617073059\n",
      "loss: 0.9149090051651001\n"
     ]
    }
   ],
   "source": [
    "# criterion output testing\n",
    "unmixing_matrix = torch.rand((selected_val_batch_data.size(0), gradient_of_layers[0].size(0)), requires_grad=True)\n",
    "reconstruction_loss = ReconstructImageFromFCLoss(32, 32, 3, 1, 1, 1)\n",
    "optimizer = torch.optim.Adam([unmixing_matrix])\n",
    "\n",
    "for iter_idx in range(25000):\n",
    "    optimizer.zero_grad()\n",
    "    # out_score, non_gaussianity_score, total_variance_score, mutual_independence_score\n",
    "    loss, _, _, _ = reconstruction_loss(unmixing_matrix, pca_whitened_gradients[0])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (iter_idx + 1) % 1000 == 0 or iter_idx == 0:\n",
    "        print('loss: {}'.format(loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T07:44:24.032875943Z",
     "start_time": "2023-12-21T07:43:44.374117314Z"
    }
   },
   "id": "d74e4a85e6c0a2e7"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    estimated_img = unmixing_matrix @ zca_whitened_gradients[0]\n",
    "    img = transforms.ToPILImage()(torch.clamp(estimated_img[4].reshape(3, 32, 32), min=-1, max=1))\n",
    "    img.show()\n",
    "    img = transforms.ToPILImage()(torch.clamp(selected_val_batch_data[4].reshape(3, 32, 32), min=-1, max=1))\n",
    "    img.show()\n",
    "    # print(estimated_img[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T08:00:55.724935545Z",
     "start_time": "2023-12-21T08:00:55.715582718Z"
    }
   },
   "id": "807441fb5cebe1d6"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([0])\n",
      "torch.Size([0])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    clamped_img = torch.clamp(estimated_img[0].reshape(3, 32, 32), min=-1, max=1)\n",
    "    print(clamped_img[clamped_img == -1].shape)\n",
    "    print(clamped_img[clamped_img == 1].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T07:42:32.281807152Z",
     "start_time": "2023-12-21T07:42:32.238458793Z"
    }
   },
   "id": "7846d02b99aa5406"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
